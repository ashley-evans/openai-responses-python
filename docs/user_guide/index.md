# User Guide

## First steps

Before getting started, make sure that you've installed [pytest](https://pytest.org/en/7.0.x/contents.html). For async support, you can see more setup instructions [here](async.md).

## Overview

This library will automatically mock any call to the OpenAI API by just decorating the test function.

!!! info

    This project does not try to generate fake responses from the models. Any part of a response that would be generated by a model will need to
    be defined by the user or will fallback to a default value.

Each endpoint has it's own [decorator](decorators.md) that can be accessed under `openai_responses.mock`. The decorator API tries to stay aligned with the OpenAI Python client API. So for chat completions, with the client you would access the endpoint with `client.chat.completions`, similarly you would access the chat completions mock with `openai_responses.mock.chat.completions`.

See all of the suppored endpoints [here](../endpoints/index.md).

For tests where you need to access multiple endpoints, you can stack or "chain" the decorators one on top of the otherand everything will still work as expected. See more in the [chaining](chaining.md) overview.

For each decorator used, a [pytest fixture](https://docs.pytest.org/en/6.2.x/fixture.html) is provided in order to access additional information about the API calls. Each fixture is an instance of a given [mock class](mocks.md). Mocks fall under 1 of 2 buckets:

1. **Stateless** for endpoints that are fully stateless
2. **Stateful** for endpoints that require keeping track of some resource state

For stateful mocks, a custom [state store](state.md) is used to keep track of the state over the course of a test or another scope.

## Example

Below is an example that covers many of the topics mentioned above.

```python linenums="1" hl_lines="7 8 14 24 25"
from openai import OpenAI

import openai_responses
from openai_responses import ChatCompletionMock


@openai_responses.mock.chat.completions( # (1)
    choices=[ # (2)
        {"message": {"content": "Hello, how can I help?"}},
        {"message": {"content": "Hi! I'm here to help!"}},
        {"message": {"content": "How can I help?"}},
    ],
)
def test_create_chat_completion(chat_completion_mock: ChatCompletionMock): # (3)
    client = OpenAI(api_key="fakeKey")
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Hello!"},
        ],
        n=3,
    )
    assert len(completion.choices) == 3 # (4)
    assert chat_completion_mock.create.route.calls.call_count == 1 # (5)
```

1. Wrap the test function with in the endpoint decorator
2. Define the choices to be returned in the response
3. Use the provided fixture for this endpoint
4. Without calling out to the API, a response with 3 valid choices was provided
5. Access route information from the mock class
